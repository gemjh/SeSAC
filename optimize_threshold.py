import os
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import product
import time
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# ah_sound.pyì˜ í•¨ìˆ˜ë“¤ì„ ì„í¬íŠ¸
import sys
sys.path.append('H:/')
from ah_sound import analyze_pitch_stability

def optimize_thresholds():
    """
    ê°€ì¥ ë†’ì€ ìƒê´€ê³„ìˆ˜ë¥¼ ì°¾ê¸° ìœ„í•œ threshold ìµœì í™” íŒŒì´í”„ë¼ì¸
    """
    print("ğŸ” Threshold ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    
    # ìµœì í™”í•  íŒŒë¼ë¯¸í„° ë²”ìœ„ ì„¤ì •
    std_thresholds = np.arange(0.5, 3.1, 0.1)  # 0.5 ~ 3.0, 0.1 ê°„ê²©
    confidence_thresholds = np.arange(0.1, 0.9, 0.05)  # 0.1 ~ 0.85, 0.05 ê°„ê²©
    window_sizes = [3, 5, 7, 9, 11]  # ë‹¤ì–‘í•œ ìœˆë„ìš° í¬ê¸°
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸í•  ì¡°í•© ìˆ˜: {len(std_thresholds) * len(confidence_thresholds) * len(window_sizes)}")
    
    # ê¸°ë³¸ ë°ì´í„° ë¡œë“œ
    folder = r'C:\Users\user\Downloads\data'
    pattern = os.path.join(folder, '**', 'CLAP_D', '0', 'p*.wav')
    wav_files = glob.glob(pattern, recursive=True)
    print(f"ğŸµ ë°œê²¬ëœ WAV íŒŒì¼ ìˆ˜: {len(wav_files)}")
    
    # ë¼ë²¨ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(r'H:\labeled_data_D.csv', header=1, index_col=0)
    label = df.loc[:, 'ah_1st_sec':'ptk_ave..1']
    ah_label = label.loc[:, 'ah_1st_sec':'ah_2nd_sec']
    
    # ìµœì í™” ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    optimization_results = []
    
    # ì „ì²´ ì¡°í•© ìˆ˜ ê³„ì‚°
    total_combinations = len(std_thresholds) * len(confidence_thresholds) * len(window_sizes)
    
    print("ğŸš€ ìµœì í™” ì‹œì‘...")
    
    # ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ì¹´ìš´í„°
    combination_count = 0
    
    for std_thresh in std_thresholds:
        for conf_thresh in confidence_thresholds:
            for win_size in window_sizes:
                combination_count += 1
                
                print(f"\nğŸ“ˆ ì§„í–‰ë¥ : {combination_count}/{total_combinations} "
                      f"({combination_count/total_combinations*100:.1f}%)")
                print(f"ğŸ¯ í˜„ì¬ í…ŒìŠ¤íŠ¸: std={std_thresh:.2f}, conf={conf_thresh:.2f}, win={win_size}")
                
                try:
                    start_time = time.time()
                    
                    # í˜„ì¬ íŒŒë¼ë¯¸í„°ë¡œ ê²°ê³¼ ê³„ì‚°
                    ah_result = pd.DataFrame(columns=['ah_1st_sec', 'ah_2nd_sec'])
                    
                    for wav_file in wav_files:
                        # Windows ê²½ë¡œ ì²˜ë¦¬ë¥¼ ìœ„í•´ replaceë¥¼ ìˆ˜ì •
                        parts = wav_file.replace(folder, '').strip(os.sep).split(os.sep)
                        if len(parts) > 0:
                            index_key = parts[0]
                        else:
                            index_key = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(wav_file))))
                        
                        if index_key not in ah_result.index:
                            ah_result.loc[index_key] = [None, None]
                        
                        filename = os.path.basename(wav_file)
                        if 'p_1_' in filename:
                            try:
                                result = analyze_pitch_stability(
                                    wav_file, 
                                    std_threshold=std_thresh,
                                    confidence_threshold=conf_thresh,
                                    window_size=win_size
                                )
                                ah_result.loc[index_key, 'ah_1st_sec'] = result
                            except Exception as e:
                                print(f"âš ï¸  íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {wav_file}: {e}")
                                continue
                    
                    # ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
                    if ah_result['ah_1st_sec'].dropna().empty:
                        print("âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                    
                    # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
                    ah_result.index = ah_result.index.astype(int)
                    combined = pd.concat([
                        ah_result['ah_1st_sec'].rename('ah_1st_sec_result'),
                        ah_label['ah_1st_sec']
                    ], axis=1, join="inner")
                    
                    # ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    if combined.dropna().empty or len(combined.dropna()) < 2:
                        print("âŒ ìƒê´€ê³„ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                    
                    corr_matrix = combined.corr()
                    correlation = corr_matrix.loc['ah_1st_sec_result', 'ah_1st_sec']
                    
                    # NaN ì²´í¬
                    if pd.isna(correlation):
                        print("âŒ ìƒê´€ê³„ìˆ˜ê°€ NaNì…ë‹ˆë‹¤.")
                        continue
                    
                    elapsed_time = time.time() - start_time
                    
                    # ê²°ê³¼ ì €ì¥
                    optimization_results.append({
                        'std_threshold': std_thresh,
                        'confidence_threshold': conf_thresh,
                        'window_size': win_size,
                        'correlation': correlation,
                        'elapsed_time': elapsed_time,
                        'valid_samples': len(combined.dropna())
                    })
                    
                    print(f"âœ… ìƒê´€ê³„ìˆ˜: {correlation:.4f}, ì²˜ë¦¬ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                    
                except Exception as e:
                    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    continue
    
    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    results_df = pd.DataFrame(optimization_results)
    
    if results_df.empty:
        print("âŒ ìµœì í™” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ê²°ê³¼ ì €ì¥
    results_df.to_csv('H:/threshold_optimization_results.csv', index=False)
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: H:/threshold_optimization_results.csv")
    
    # ìµœê³  ìƒê´€ê³„ìˆ˜ ì°¾ê¸°
    best_result = results_df.loc[results_df['correlation'].idxmax()]
    
    print("\nğŸ† ìµœì í™” ê²°ê³¼:")
    print("="*50)
    print(f"ìµœê³  ìƒê´€ê³„ìˆ˜: {best_result['correlation']:.6f}")
    print(f"ìµœì  std_threshold: {best_result['std_threshold']:.2f}")
    print(f"ìµœì  confidence_threshold: {best_result['confidence_threshold']:.2f}")
    print(f"ìµœì  window_size: {int(best_result['window_size'])}")
    print(f"ìœ íš¨ ìƒ˜í”Œ ìˆ˜: {int(best_result['valid_samples'])}")
    print(f"ì²˜ë¦¬ ì‹œê°„: {best_result['elapsed_time']:.2f}ì´ˆ")
    print("="*50)
    
    return results_df, best_result

def visualize_optimization_results(results_df):
    """
    ìµœì í™” ê²°ê³¼ë¥¼ ì‹œê°í™”
    """
    print("ğŸ“Š ê²°ê³¼ ì‹œê°í™” ì¤‘...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. ìƒê´€ê³„ìˆ˜ íˆìŠ¤í† ê·¸ë¨
    axes[0, 0].hist(results_df['correlation'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, 0].set_xlabel('Correlation Coefficient')
    axes[0, 0].set_ylabel('Frequency')
    axes[0, 0].set_title('Distribution of Correlation Coefficients')
    axes[0, 0].axvline(results_df['correlation'].max(), color='red', linestyle='--', 
                       label=f'Max: {results_df["correlation"].max():.4f}')
    axes[0, 0].legend()
    
    # 2. std_threshold vs correlation
    scatter = axes[0, 1].scatter(results_df['std_threshold'], results_df['correlation'], 
                                c=results_df['confidence_threshold'], cmap='viridis', alpha=0.6)
    axes[0, 1].set_xlabel('STD Threshold')
    axes[0, 1].set_ylabel('Correlation Coefficient')
    axes[0, 1].set_title('STD Threshold vs Correlation (colored by Confidence Threshold)')
    plt.colorbar(scatter, ax=axes[0, 1], label='Confidence Threshold')
    
    # 3. confidence_threshold vs correlation
    scatter2 = axes[1, 0].scatter(results_df['confidence_threshold'], results_df['correlation'], 
                                 c=results_df['window_size'], cmap='plasma', alpha=0.6)
    axes[1, 0].set_xlabel('Confidence Threshold')
    axes[1, 0].set_ylabel('Correlation Coefficient')
    axes[1, 0].set_title('Confidence Threshold vs Correlation (colored by Window Size)')
    plt.colorbar(scatter2, ax=axes[1, 0], label='Window Size')
    
    # 4. Top 10 ê²°ê³¼
    top_10 = results_df.nlargest(10, 'correlation')
    axes[1, 1].barh(range(len(top_10)), top_10['correlation'])
    axes[1, 1].set_yticks(range(len(top_10)))
    axes[1, 1].set_yticklabels([f"std:{row['std_threshold']:.1f}, conf:{row['confidence_threshold']:.2f}, win:{int(row['window_size'])}" 
                               for _, row in top_10.iterrows()])
    axes[1, 1].set_xlabel('Correlation Coefficient')
    axes[1, 1].set_title('Top 10 Parameter Combinations')
    
    plt.tight_layout()
    plt.savefig('H:/threshold_optimization_visualization.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 3D ì‹œê°í™” (ì„ íƒì )
    fig = plt.figure(figsize=(12, 8))
    ax = fig.add_subplot(111, projection='3d')
    
    scatter = ax.scatter(results_df['std_threshold'], 
                        results_df['confidence_threshold'], 
                        results_df['correlation'],
                        c=results_df['window_size'], 
                        cmap='coolwarm', 
                        s=50, 
                        alpha=0.6)
    
    ax.set_xlabel('STD Threshold')
    ax.set_ylabel('Confidence Threshold')
    ax.set_zlabel('Correlation Coefficient')
    ax.set_title('3D Optimization Results')
    plt.colorbar(scatter, label='Window Size')
    
    plt.savefig('H:/threshold_optimization_3d.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("ğŸ’¾ ì‹œê°í™” ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
    print("  - H:/threshold_optimization_visualization.png")
    print("  - H:/threshold_optimization_3d.png")

def analyze_parameter_sensitivity(results_df):
    """
    ê° íŒŒë¼ë¯¸í„°ì˜ ë¯¼ê°ë„ ë¶„ì„
    """
    print("ğŸ”¬ íŒŒë¼ë¯¸í„° ë¯¼ê°ë„ ë¶„ì„...")
    
    # ê° íŒŒë¼ë¯¸í„°ë³„ í‰ê·  ìƒê´€ê³„ìˆ˜
    std_sensitivity = results_df.groupby('std_threshold')['correlation'].agg(['mean', 'std', 'count'])
    conf_sensitivity = results_df.groupby('confidence_threshold')['correlation'].agg(['mean', 'std', 'count'])
    win_sensitivity = results_df.groupby('window_size')['correlation'].agg(['mean', 'std', 'count'])
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“ˆ STD Threshold ë¯¼ê°ë„:")
    print(f"ìµœê³  í‰ê·  ìƒê´€ê³„ìˆ˜: {std_sensitivity['mean'].max():.4f} (std_threshold: {std_sensitivity['mean'].idxmax():.2f})")
    
    print("\nğŸ“ˆ Confidence Threshold ë¯¼ê°ë„:")
    print(f"ìµœê³  í‰ê·  ìƒê´€ê³„ìˆ˜: {conf_sensitivity['mean'].max():.4f} (confidence_threshold: {conf_sensitivity['mean'].idxmax():.2f})")
    
    print("\nğŸ“ˆ Window Size ë¯¼ê°ë„:")
    print(f"ìµœê³  í‰ê·  ìƒê´€ê³„ìˆ˜: {win_sensitivity['mean'].max():.4f} (window_size: {int(win_sensitivity['mean'].idxmax())})")
    
    # ë¯¼ê°ë„ ì‹œê°í™”
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    
    # STD Threshold
    axes[0].errorbar(std_sensitivity.index, std_sensitivity['mean'], 
                     yerr=std_sensitivity['std'], capsize=3, marker='o')
    axes[0].set_xlabel('STD Threshold')
    axes[0].set_ylabel('Mean Correlation')
    axes[0].set_title('STD Threshold Sensitivity')
    axes[0].grid(True, alpha=0.3)
    
    # Confidence Threshold
    axes[1].errorbar(conf_sensitivity.index, conf_sensitivity['mean'], 
                     yerr=conf_sensitivity['std'], capsize=3, marker='s')
    axes[1].set_xlabel('Confidence Threshold')
    axes[1].set_ylabel('Mean Correlation')
    axes[1].set_title('Confidence Threshold Sensitivity')
    axes[1].grid(True, alpha=0.3)
    
    # Window Size
    axes[2].errorbar(win_sensitivity.index, win_sensitivity['mean'], 
                     yerr=win_sensitivity['std'], capsize=3, marker='^')
    axes[2].set_xlabel('Window Size')
    axes[2].set_ylabel('Mean Correlation')
    axes[2].set_title('Window Size Sensitivity')
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('H:/parameter_sensitivity_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return std_sensitivity, conf_sensitivity, win_sensitivity

if __name__ == "__main__":
    # ìµœì í™” ì‹¤í–‰
    results_df, best_result = optimize_thresholds()
    
    if results_df is not None and not results_df.empty:
        # ê²°ê³¼ ì‹œê°í™”
        visualize_optimization_results(results_df)
        
        # ë¯¼ê°ë„ ë¶„ì„
        std_sens, conf_sens, win_sens = analyze_parameter_sensitivity(results_df)
        
        # ìµœì¢… ë³´ê³ ì„œ ì €ì¥
        with open('H:/optimization_report.txt', 'w', encoding='utf-8') as f:
            f.write("ğŸ† Threshold ìµœì í™” ë³´ê³ ì„œ\n")
            f.write("="*50 + "\n\n")
            f.write(f"ìµœê³  ìƒê´€ê³„ìˆ˜: {best_result['correlation']:.6f}\n")
            f.write(f"ìµœì  std_threshold: {best_result['std_threshold']:.2f}\n")
            f.write(f"ìµœì  confidence_threshold: {best_result['confidence_threshold']:.2f}\n")
            f.write(f"ìµœì  window_size: {int(best_result['window_size'])}\n")
            f.write(f"ìœ íš¨ ìƒ˜í”Œ ìˆ˜: {int(best_result['valid_samples'])}\n")
            f.write(f"ì²˜ë¦¬ ì‹œê°„: {best_result['elapsed_time']:.2f}ì´ˆ\n\n")
            
            f.write("ğŸ“Š ìƒìœ„ 10ê°œ ê²°ê³¼:\n")
            f.write("-"*30 + "\n")
            top_10 = results_df.nlargest(10, 'correlation')
            for idx, (_, row) in enumerate(top_10.iterrows(), 1):
                f.write(f"{idx:2d}. ìƒê´€ê³„ìˆ˜: {row['correlation']:.4f} | "
                       f"std: {row['std_threshold']:.2f} | "
                       f"conf: {row['confidence_threshold']:.2f} | "
                       f"win: {int(row['window_size'])}\n")
        
        print("\nğŸ’¾ ìµœì¢… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: H:/optimization_report.txt")
        print("ğŸ‰ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    else:
        print("âŒ ìµœì í™” ì‹¤íŒ¨: ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
# -*- coding: utf-8 -*-
"""talk_pic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19deKgqW0f74BMUriOixtr1YWKVHi1E70
"""

import numpy as np
import librosa
import torch
import os
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from tensorflow.keras.models import load_model
import tensorflow as tf  # tf import 추가 - 2025.08.22

# ====== 설정 ======
MODEL_PATH = os.path.join(os.path.dirname(__file__), "multilabel_whisper_attn_medium.keras")
THRESHOLD = 0.38
MAX_TOKEN_LENGTH = 256
SAMPLE_RATE = 16000
N_MELS = 128

# ====== 라벨 (원래 학습에 썼던 target_words를 그대로 두세요) ======
target_words = [
    "책가방","아이","현관","신발","강아지","꼬리","엄마","소파","뜨개질","아빠","신문",
    "텔레비전","테이블","로봇","라디오","창문","나무","참새","책장","책","달력",
    "시계","가족사진","강아지집","밥그릇","식탁","주전자","찻잔","과일","액자"
]
NUM_LABELS = len(target_words)

# ============================================================================
# 전역 모델 로딩 제거 및 동적 로딩으로 변경 - 2025.08.22 수정
# 메모리 누수 방지를 위해 필요할 때만 모델 로드
# ============================================================================

# 전역 변수들을 None으로 초기화
device = None
processor = None
whisper_model = None

def _load_models():
    """모델들을 동적으로 로드하는 함수 - 2025.08.22 추가"""
    global device, processor, whisper_model
    
    # Whisper 모델 로드
    if device is None or processor is None or whisper_model is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        processor = WhisperProcessor.from_pretrained("openai/whisper-medium")
        whisper_model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-medium").to(device)
        whisper_model.eval()
    
    # Keras 모델 로드 (매번 새로 로드하여 메모리 관리)
    model = load_model(MODEL_PATH)
    
    return device, processor, whisper_model, model

# ====== 전처리 함수 ======
def load_wav_to_mel(wav_path, sr=SAMPLE_RATE, n_mels=N_MELS):
    y, _ = librosa.load(wav_path, sr=sr, mono=True)
    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)
    mel_db = librosa.power_to_db(mel, ref=np.max)
    mel_norm = (mel_db + 80) / 80.0
    mel_norm = mel_norm.astype(np.float32)
    return np.expand_dims(mel_norm, axis=-1)

@torch.no_grad()
def extract_token_ids_from_wav(wav_path):
    # ============================================================================
    # 동적 모델 로딩 사용 - 2025.08.22 수정
    # ============================================================================
    device, processor, whisper_model, _ = _load_models()
    
    speech_array, _ = librosa.load(wav_path, sr=SAMPLE_RATE, mono=True)
    inputs = processor(speech_array, sampling_rate=SAMPLE_RATE, return_tensors="pt")
    input_features = inputs.input_features.to(device)

    predicted_ids = whisper_model.generate(
        input_features,
        max_new_tokens=MAX_TOKEN_LENGTH
    )
    token_ids = predicted_ids[0].cpu().numpy().astype(np.int32)

    # 패딩/자르기
    if token_ids.shape[0] < MAX_TOKEN_LENGTH:
        pad = np.zeros(MAX_TOKEN_LENGTH - token_ids.shape[0], dtype=np.int32)
        token_ids = np.concatenate([token_ids, pad], axis=0)
    else:
        token_ids = token_ids[:MAX_TOKEN_LENGTH]
    return token_ids

def prepare_inputs_for_inference(wav_path):
    mel = load_wav_to_mel(wav_path)          # (128, T, 1)
    mel = np.expand_dims(mel, axis=0)        # (1, 128, T, 1)

    token_ids = extract_token_ids_from_wav(wav_path)   # (MAX_TOKEN_LENGTH,)
    token_ids = np.expand_dims(token_ids, axis=0)      # (1, MAX_TOKEN_LENGTH)
    return mel, token_ids

# ====== 예측 및 점수 계산 (임계값 이상 개수만 점수로) ======
def score_audio(wav_path, threshold=THRESHOLD, label_names=target_words):
    # ============================================================================
    # 모델 동적 로딩 및 메모리 정리 추가 - 2025.08.22 수정
    # ============================================================================
    _, _, _, model = _load_models()
    
    try:
        X_mel, X_tok = prepare_inputs_for_inference(wav_path)
        pred = model.predict([X_mel, X_tok], verbose=0)[0]   # (NUM_LABELS,)
        count = int(np.sum(pred >= threshold))
        # print(f"\n파일: {wav_path}")
        # print(f"총점: {count} / {len(label_names)}")
        return count
    finally:
        # ============================================================================
        # 메모리 정리 - 2025.08.22 추가  
        # 예측 완료 후 Keras 모델과 TensorFlow 세션을 정리하여 메모리 확보
        # ============================================================================
        try:
            if 'model' in locals():
                del model
        except:
            pass
        tf.keras.backend.clear_session()

# 사용 예시
# wav_file = r"C:\Users\ous37\Downloads\임상data(폴더명 수정)\3019\CLAP_A\7\p_1_0.wav"
# score_audio(wav_file, model, threshold=THRESHOLD)
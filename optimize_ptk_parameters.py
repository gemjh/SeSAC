import os
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import product
import time
import warnings
warnings.filterwarnings('ignore')

# ptk_sound.pyì˜ í•¨ìˆ˜ë“¤ì„ ì„í¬íŠ¸
import sys
sys.path.append('H:/')

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
import librosa
import scipy.signal
from pydub import AudioSegment

def convert_audio_for_model(user_file, output_file=None, EXPECTED_SAMPLE_RATE=16000):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ëª¨ë¸ì— ë§ê²Œ ë³€í™˜ (ëª¨ë…¸ì±„ë„ + ì •ê·œí™”)"""
    import tempfile
    import uuid
    
    if output_file is None:
        # ê³ ìœ í•œ ì„ì‹œ íŒŒì¼ëª… ìƒì„±
        output_file = os.path.join(tempfile.gettempdir(), f"converted_audio_{uuid.uuid4().hex}.wav")
    
    audio = AudioSegment.from_file(user_file)
    audio = audio.set_frame_rate(EXPECTED_SAMPLE_RATE).set_channels(1)
    audio.export(output_file, format="wav")
    return output_file

def count_peaks_from_waveform_optimized(filepath, height=0.05, distance=3000, plot=False):
    """
    ìµœì í™”ëœ í”¼í¬ ì¹´ìš´íŒ… í•¨ìˆ˜ (ptk_sound.pyì—ì„œ ê°€ì ¸ì˜´)
    """
    temp_file = None
    try:
        temp_file = convert_audio_for_model(filepath)
        y, sr = librosa.load(temp_file, sr=None)
        # 3ì´ˆ ìë¥´ê¸°
        y_trimmed = y[:sr * 3]
        
        if np.max(np.abs(y_trimmed)) == 0:
            return 0
            
        y_trimmed = y_trimmed / np.max(np.abs(y_trimmed))
        
        # í”¼í¬ íƒì§€
        peaks, _ = scipy.signal.find_peaks(y_trimmed, height=height, distance=distance)
        
        if plot:
            plt.figure(figsize=(12, 4))
            plt.plot(y_trimmed)
            plt.plot(peaks, y_trimmed[peaks], "rx")
            plt.title(f"Detected Peaks: {len(peaks)}")
            plt.show()
            
        return len(peaks)
    except Exception as e:
        print(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {filepath}: {e}")
        return 0
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if temp_file and os.path.exists(temp_file):
            try:
                os.remove(temp_file)
            except:
                pass

def optimize_ptk_parameters():
    """
    PTK íŒŒë¼ë¯¸í„° ìµœì í™” íŒŒì´í”„ë¼ì¸
    """
    print("ğŸ” PTK íŒŒë¼ë¯¸í„° ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    
    # ìµœì í™”í•  íŒŒë¼ë¯¸í„° ë²”ìœ„ ì„¤ì • (ì›ë³¸ íŒŒë¼ë¯¸í„° ì£¼ë³€ì—ì„œ ì„¸ë°€í•˜ê²Œ)
    height_values = np.arange(0.02, 0.12, 0.005)  # 0.02 ~ 0.115, 0.005 ê°„ê²© (ì›ë³¸ 0.05 ì£¼ë³€)
    distance_values = np.arange(2000, 5000, 200)  # 2000 ~ 4800, 200 ê°„ê²© (ì›ë³¸ 3000 ì£¼ë³€)
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸í•  ì¡°í•© ìˆ˜: {len(height_values) * len(distance_values)}")
    
    # ë°ì´í„° ë¡œë“œ
    folder = r'C:\Users\user\Downloads\data'
    pattern = os.path.join(folder, '**', 'CLAP_D', '1', 'p*.wav')
    wav_files = glob.glob(pattern, recursive=True)
    print(f"ğŸµ ë°œê²¬ëœ WAV íŒŒì¼ ìˆ˜: {len(wav_files)}")
    
    # ë¼ë²¨ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(r'H:\labeled_data_D.csv', header=1, index_col=0)
    ptk_label = df.loc[:, ['peo_2nd', 'teo_2nd', 'keo_2nd', 'ptk_2nd']]
    
    # ìµœì í™” ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    optimization_results = []
    
    total_combinations = len(height_values) * len(distance_values)
    combination_count = 0
    
    print("ğŸš€ ìµœì í™” ì‹œì‘...")
    
    for height in height_values:
        for distance in distance_values:
            combination_count += 1
            
            print(f"\nğŸ“ˆ ì§„í–‰ë¥ : {combination_count}/{total_combinations} "
                  f"({combination_count/total_combinations*100:.1f}%)")
            print(f"ğŸ¯ í˜„ì¬ í…ŒìŠ¤íŠ¸: height={height:.3f}, distance={int(distance)}")
            
            try:
                start_time = time.time()
                
                # í˜„ì¬ íŒŒë¼ë¯¸í„°ë¡œ ê²°ê³¼ ê³„ì‚°
                ptk_result = pd.DataFrame(columns=['peo_2nd', 'teo_2nd', 'keo_2nd', 'ptk_2nd'])
                
                for wav_file in wav_files:
                    # Windows ê²½ë¡œ ì²˜ë¦¬ë¥¼ ìœ„í•´ replaceë¥¼ ìˆ˜ì •
                    parts = wav_file.replace(folder, '').strip(os.sep).split(os.sep)
                    if len(parts) > 0:
                        index_key = parts[0]
                    else:
                        index_key = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(wav_file))))
                    
                    if index_key not in ptk_result.index:
                        ptk_result.loc[index_key] = [None, None, None, None]
                    
                    filename = os.path.basename(wav_file)
                    
                    # ê° ìŒì„± ìœ í˜•ë³„ë¡œ í”¼í¬ ì¹´ìš´íŠ¸
                    if 'p_2_' in filename:  # peo_2nd
                        result = count_peaks_from_waveform_optimized(wav_file, height=height, distance=distance)
                        ptk_result.loc[index_key, 'peo_2nd'] = result
                    elif 'p_5_' in filename:  # teo_2nd
                        result = count_peaks_from_waveform_optimized(wav_file, height=height, distance=distance)
                        ptk_result.loc[index_key, 'teo_2nd'] = result
                    elif 'p_7_' in filename:  # keo_2nd
                        result = count_peaks_from_waveform_optimized(wav_file, height=height, distance=distance)
                        ptk_result.loc[index_key, 'keo_2nd'] = result
                    elif 'p_10_' in filename:  # ptk_2nd
                        result = count_peaks_from_waveform_optimized(wav_file, height=height, distance=distance)
                        ptk_result.loc[index_key, 'ptk_2nd'] = round(result/3, 1)
                
                # ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
                if ptk_result.dropna(how='all').empty:
                    print("âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # ìƒê´€ê³„ìˆ˜ ê³„ì‚° - ê° ì—´ë³„ë¡œ
                ptk_result.index = ptk_result.index.astype(int)
                correlation_results = {}
                
                for col in ptk_result.columns:
                    if col in ptk_label.columns:
                        # ì¸ë±ìŠ¤ë¥¼ ë§ì¶˜ í›„ NaN ê°’ ì œê±°í•˜ì—¬ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
                        combined = pd.concat([ptk_result[col], ptk_label[col]], axis=1, join="inner").dropna()
                        
                        if not combined.empty and len(combined) > 1:
                            correlation = combined.corr(method='pearson').iloc[0, 1]
                            if not pd.isna(correlation):
                                correlation_results[col] = correlation
                            else:
                                correlation_results[col] = 0
                        else:
                            correlation_results[col] = 0
                
                if not correlation_results:
                    print("âŒ ìƒê´€ê³„ìˆ˜ ê³„ì‚° ì‹¤íŒ¨")
                    continue
                
                # í‰ê·  ìƒê´€ê³„ìˆ˜ ê³„ì‚°
                avg_correlation = np.mean(list(correlation_results.values()))
                max_correlation = max(correlation_results.values())
                
                elapsed_time = time.time() - start_time
                
                # ê²°ê³¼ ì €ì¥
                result_entry = {
                    'height': height,
                    'distance': distance,
                    'avg_correlation': avg_correlation,
                    'max_correlation': max_correlation,
                    'elapsed_time': elapsed_time,
                    'valid_samples': len(ptk_result.dropna(how='all'))
                }
                
                # ê° ì—´ë³„ ìƒê´€ê³„ìˆ˜ë„ ì €ì¥
                for col, corr in correlation_results.items():
                    result_entry[f'{col}_correlation'] = corr
                
                optimization_results.append(result_entry)
                
                print(f"âœ… í‰ê·  ìƒê´€ê³„ìˆ˜: {avg_correlation:.4f}, ìµœëŒ€: {max_correlation:.4f}, ì²˜ë¦¬ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
    
    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    results_df = pd.DataFrame(optimization_results)
    
    if results_df.empty:
        print("âŒ ìµœì í™” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    
    # ê²°ê³¼ ì €ì¥
    results_df.to_csv('H:/ptk_optimization_results.csv', index=False)
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: H:/ptk_optimization_results.csv")
    
    # í‰ê·  ìƒê´€ê³„ìˆ˜ ê¸°ì¤€ ìµœê³  ê²°ê³¼
    best_avg = results_df.loc[results_df['avg_correlation'].idxmax()]
    
    # ìµœëŒ€ ìƒê´€ê³„ìˆ˜ ê¸°ì¤€ ìµœê³  ê²°ê³¼
    best_max = results_df.loc[results_df['max_correlation'].idxmax()]
    
    print("\nğŸ† ìµœì í™” ê²°ê³¼ (í‰ê·  ìƒê´€ê³„ìˆ˜ ê¸°ì¤€):")
    print("="*60)
    print(f"ìµœê³  í‰ê·  ìƒê´€ê³„ìˆ˜: {best_avg['avg_correlation']:.6f}")
    print(f"ìµœì  height: {best_avg['height']:.3f}")
    print(f"ìµœì  distance: {int(best_avg['distance'])}")
    print(f"ìœ íš¨ ìƒ˜í”Œ ìˆ˜: {int(best_avg['valid_samples'])}")
    print(f"ì²˜ë¦¬ ì‹œê°„: {best_avg['elapsed_time']:.2f}ì´ˆ")
    
    print("\nğŸ¯ ê°œë³„ ì—´ ìƒê´€ê³„ìˆ˜:")
    for col in ['peo_2nd', 'teo_2nd', 'keo_2nd', 'ptk_2nd']:
        if f'{col}_correlation' in best_avg:
            print(f"  {col}: {best_avg[f'{col}_correlation']:.4f}")
    print("="*60)
    
    print("\nğŸ† ìµœì í™” ê²°ê³¼ (ìµœëŒ€ ìƒê´€ê³„ìˆ˜ ê¸°ì¤€):")
    print("="*60)
    print(f"ìµœê³  ìµœëŒ€ ìƒê´€ê³„ìˆ˜: {best_max['max_correlation']:.6f}")
    print(f"ìµœì  height: {best_max['height']:.3f}")
    print(f"ìµœì  distance: {int(best_max['distance'])}")
    print("="*60)
    
    return results_df, best_avg, best_max

def visualize_ptk_optimization_results(results_df):
    """
    PTK ìµœì í™” ê²°ê³¼ë¥¼ ì‹œê°í™”
    """
    print("ğŸ“Š ê²°ê³¼ ì‹œê°í™” ì¤‘...")
    
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    
    # 1. í‰ê·  ìƒê´€ê³„ìˆ˜ íˆìŠ¤í† ê·¸ë¨
    axes[0, 0].hist(results_df['avg_correlation'], bins=30, alpha=0.7, color='lightblue', edgecolor='black')
    axes[0, 0].set_xlabel('Average Correlation Coefficient')
    axes[0, 0].set_ylabel('Frequency')
    axes[0, 0].set_title('Distribution of Average Correlation Coefficients')
    axes[0, 0].axvline(results_df['avg_correlation'].max(), color='red', linestyle='--', 
                       label=f'Max: {results_df["avg_correlation"].max():.4f}')
    axes[0, 0].legend()
    
    # 2. Height vs í‰ê·  ìƒê´€ê³„ìˆ˜
    scatter1 = axes[0, 1].scatter(results_df['height'], results_df['avg_correlation'], 
                                 c=results_df['distance'], cmap='viridis', alpha=0.6)
    axes[0, 1].set_xlabel('Height Threshold')
    axes[0, 1].set_ylabel('Average Correlation Coefficient')
    axes[0, 1].set_title('Height vs Average Correlation (colored by Distance)')
    plt.colorbar(scatter1, ax=axes[0, 1], label='Distance')
    
    # 3. Distance vs í‰ê·  ìƒê´€ê³„ìˆ˜
    scatter2 = axes[0, 2].scatter(results_df['distance'], results_df['avg_correlation'], 
                                 c=results_df['height'], cmap='plasma', alpha=0.6)
    axes[0, 2].set_xlabel('Distance Threshold')
    axes[0, 2].set_ylabel('Average Correlation Coefficient')
    axes[0, 2].set_title('Distance vs Average Correlation (colored by Height)')
    plt.colorbar(scatter2, ax=axes[0, 2], label='Height')
    
    # 4. íˆíŠ¸ë§µ - Height vs Distance
    pivot_table = results_df.pivot_table(values='avg_correlation', index='height', columns='distance', aggfunc='mean')
    im = axes[1, 0].imshow(pivot_table.values, aspect='auto', cmap='RdYlBu_r', origin='lower')
    axes[1, 0].set_xlabel('Distance Index')
    axes[1, 0].set_ylabel('Height Index')
    axes[1, 0].set_title('Average Correlation Heatmap')
    plt.colorbar(im, ax=axes[1, 0])
    
    # 5. Top 10 ê²°ê³¼
    top_10 = results_df.nlargest(10, 'avg_correlation')
    axes[1, 1].barh(range(len(top_10)), top_10['avg_correlation'])
    axes[1, 1].set_yticks(range(len(top_10)))
    axes[1, 1].set_yticklabels([f"h:{row['height']:.3f}, d:{int(row['distance'])}" 
                               for _, row in top_10.iterrows()])
    axes[1, 1].set_xlabel('Average Correlation Coefficient')
    axes[1, 1].set_title('Top 10 Parameter Combinations')
    
    # 6. ê°œë³„ ì—´ ìƒê´€ê³„ìˆ˜ ë¹„êµ (ìƒìœ„ 5ê°œ)
    top_5 = results_df.nlargest(5, 'avg_correlation')
    cols = ['peo_2nd_correlation', 'teo_2nd_correlation', 'keo_2nd_correlation', 'ptk_2nd_correlation']
    
    for i, (_, row) in enumerate(top_5.iterrows()):
        values = [row.get(col, 0) for col in cols]
        axes[1, 2].bar([j + i*0.15 for j in range(len(cols))], values, 
                      width=0.15, label=f"h:{row['height']:.3f}, d:{int(row['distance'])}", alpha=0.7)
    
    axes[1, 2].set_xlabel('PTK Columns')
    axes[1, 2].set_ylabel('Correlation Coefficient')
    axes[1, 2].set_title('Individual Column Correlations (Top 5)')
    axes[1, 2].set_xticks(range(len(cols)))
    axes[1, 2].set_xticklabels(['peo_2nd', 'teo_2nd', 'keo_2nd', 'ptk_2nd'])
    axes[1, 2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    
    plt.tight_layout()
    plt.savefig('H:/ptk_optimization_visualization.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 3D ì‹œê°í™”
    fig = plt.figure(figsize=(12, 8))
    ax = fig.add_subplot(111, projection='3d')
    
    scatter = ax.scatter(results_df['height'], 
                        results_df['distance'], 
                        results_df['avg_correlation'],
                        c=results_df['max_correlation'], 
                        cmap='coolwarm', 
                        s=50, 
                        alpha=0.6)
    
    ax.set_xlabel('Height Threshold')
    ax.set_ylabel('Distance Threshold')
    ax.set_zlabel('Average Correlation Coefficient')
    ax.set_title('3D PTK Parameter Optimization Results')
    plt.colorbar(scatter, label='Max Correlation')
    
    plt.savefig('H:/ptk_optimization_3d.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("ğŸ’¾ ì‹œê°í™” ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
    print("  - H:/ptk_optimization_visualization.png")
    print("  - H:/ptk_optimization_3d.png")

def analyze_ptk_parameter_sensitivity(results_df):
    """
    PTK íŒŒë¼ë¯¸í„°ì˜ ë¯¼ê°ë„ ë¶„ì„
    """
    print("ğŸ”¬ PTK íŒŒë¼ë¯¸í„° ë¯¼ê°ë„ ë¶„ì„...")
    
    # ê° íŒŒë¼ë¯¸í„°ë³„ í‰ê·  ìƒê´€ê³„ìˆ˜
    height_sensitivity = results_df.groupby('height')['avg_correlation'].agg(['mean', 'std', 'count'])
    distance_sensitivity = results_df.groupby('distance')['avg_correlation'].agg(['mean', 'std', 'count'])
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“ˆ Height Threshold ë¯¼ê°ë„:")
    print(f"ìµœê³  í‰ê·  ìƒê´€ê³„ìˆ˜: {height_sensitivity['mean'].max():.4f} (height: {height_sensitivity['mean'].idxmax():.3f})")
    
    print("\nğŸ“ˆ Distance Threshold ë¯¼ê°ë„:")
    print(f"ìµœê³  í‰ê·  ìƒê´€ê³„ìˆ˜: {distance_sensitivity['mean'].max():.4f} (distance: {int(distance_sensitivity['mean'].idxmax())})")
    
    # ë¯¼ê°ë„ ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # Height Threshold
    axes[0].errorbar(height_sensitivity.index, height_sensitivity['mean'], 
                     yerr=height_sensitivity['std'], capsize=3, marker='o')
    axes[0].set_xlabel('Height Threshold')
    axes[0].set_ylabel('Mean Average Correlation')
    axes[0].set_title('Height Threshold Sensitivity')
    axes[0].grid(True, alpha=0.3)
    
    # Distance Threshold
    axes[1].errorbar(distance_sensitivity.index, distance_sensitivity['mean'], 
                     yerr=distance_sensitivity['std'], capsize=3, marker='s')
    axes[1].set_xlabel('Distance Threshold')
    axes[1].set_ylabel('Mean Average Correlation')
    axes[1].set_title('Distance Threshold Sensitivity')
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('H:/ptk_parameter_sensitivity_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return height_sensitivity, distance_sensitivity

if __name__ == "__main__":
    # ìµœì í™” ì‹¤í–‰
    result = optimize_ptk_parameters()
    
    if result[0] is not None:
        results_df, best_avg, best_max = result
        
        # ê²°ê³¼ ì‹œê°í™”
        visualize_ptk_optimization_results(results_df)
        
        # ë¯¼ê°ë„ ë¶„ì„
        height_sens, distance_sens = analyze_ptk_parameter_sensitivity(results_df)
        
        # ìµœì¢… ë³´ê³ ì„œ ì €ì¥
        with open('H:/ptk_optimization_report.txt', 'w', encoding='utf-8') as f:
            f.write("ğŸ† PTK íŒŒë¼ë¯¸í„° ìµœì í™” ë³´ê³ ì„œ\n")
            f.write("="*60 + "\n\n")
            
            f.write("ğŸ“Š í‰ê·  ìƒê´€ê³„ìˆ˜ ê¸°ì¤€ ìµœì  ê²°ê³¼:\n")
            f.write(f"ìµœê³  í‰ê·  ìƒê´€ê³„ìˆ˜: {best_avg['avg_correlation']:.6f}\n")
            f.write(f"ìµœì  height: {best_avg['height']:.3f}\n")
            f.write(f"ìµœì  distance: {int(best_avg['distance'])}\n")
            f.write(f"ìœ íš¨ ìƒ˜í”Œ ìˆ˜: {int(best_avg['valid_samples'])}\n")
            f.write(f"ì²˜ë¦¬ ì‹œê°„: {best_avg['elapsed_time']:.2f}ì´ˆ\n\n")
            
            f.write("ğŸ¯ ê°œë³„ ì—´ë³„ ìƒê´€ê³„ìˆ˜ (í‰ê·  ê¸°ì¤€):\n")
            for col in ['peo_2nd', 'teo_2nd', 'keo_2nd', 'ptk_2nd']:
                if f'{col}_correlation' in best_avg:
                    f.write(f"  {col}: {best_avg[f'{col}_correlation']:.4f}\n")
            f.write("\n")
            
            f.write("ğŸ“Š ìµœëŒ€ ìƒê´€ê³„ìˆ˜ ê¸°ì¤€ ìµœì  ê²°ê³¼:\n")
            f.write(f"ìµœê³  ìµœëŒ€ ìƒê´€ê³„ìˆ˜: {best_max['max_correlation']:.6f}\n")
            f.write(f"ìµœì  height: {best_max['height']:.3f}\n")
            f.write(f"ìµœì  distance: {int(best_max['distance'])}\n\n")
            
            f.write("ğŸ“Š ìƒìœ„ 10ê°œ ê²°ê³¼ (í‰ê·  ìƒê´€ê³„ìˆ˜ ê¸°ì¤€):\n")
            f.write("-"*40 + "\n")
            top_10 = results_df.nlargest(10, 'avg_correlation')
            for idx, (_, row) in enumerate(top_10.iterrows(), 1):
                f.write(f"{idx:2d}. í‰ê·  ìƒê´€ê³„ìˆ˜: {row['avg_correlation']:.4f} | "
                       f"height: {row['height']:.3f} | "
                       f"distance: {int(row['distance'])}\n")
        
        print("\nğŸ’¾ ìµœì¢… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: H:/ptk_optimization_report.txt")
        print("ğŸ‰ PTK ìµœì í™” íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    else:
        print("âŒ PTK ìµœì í™” ì‹¤íŒ¨: ìœ íš¨í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SPICE ëª¨ë¸ì„ ì •ë§ë¡œ ì‹¤í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
TensorFlow 1.x ì™„ì „ í˜¸í™˜ ëª¨ë“œ ì‚¬ìš©
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow.compat.v1 as tf
tf.disable_eager_execution()  # Eager execution ì™„ì „ ë¹„í™œì„±í™”
tf.enable_resource_variables()  # Resource variables í™œì„±í™”

import tensorflow_hub as hub
import numpy as np
import matplotlib.pyplot as plt
import glob
from scipy.io import wavfile
from pydub import AudioSegment
import warnings
warnings.filterwarnings('ignore')

print("TensorFlow:", tf.__version__)
print("Eager execution ë¹„í™œì„±í™”ë¨:", not tf.executing_eagerly())

# ìƒìˆ˜
EXPECTED_SAMPLE_RATE = 16000
MAX_ABS_INT16 = 32768.0

def convert_audio_for_model(data):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì„ ëª¨ë¸ì— ë§ê²Œ ë³€í™˜"""
    if not isinstance(data, list):
        data = [data]

    result = []
    save_dir = "./converted_output"
    os.makedirs(save_dir, exist_ok=True)

    for file in data:
        try:
            audio = AudioSegment.from_file(file)
            audio = audio.set_frame_rate(EXPECTED_SAMPLE_RATE).set_channels(1)
            
            base_name = os.path.basename(file)
            safe_name = ''.join(c if c.isalnum() or c in '._-' else '_' for c in base_name)
            output_path = os.path.join(save_dir, 'converted_' + safe_name)
            
            audio.export(output_path, format="wav")
            result.append(output_path.split('/')[-1])
            
        except Exception as e:
            print(f"[ERROR] íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: {file} â†’ {e}")
    
    return result

def main():
    print("SPICE ëª¨ë¸ ì‹¤í–‰ ì‹œì‘...")
    
    # ì˜¤ë””ì˜¤ íŒŒì¼ ì¤€ë¹„
    data_folder = "0_ì•„"
    audio_file_list = glob.glob(os.path.join(data_folder, "*.wav"))
    converted_file_lst = convert_audio_for_model(audio_file_list)
    
    if not converted_file_lst:
        print("ë³€í™˜ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì²« ë²ˆì§¸ íŒŒì¼ ë¡œë“œ
    converted_audio_file = converted_file_lst[0]
    dr = "converted_output/"
    sample_rate, audio_samples = wavfile.read(dr + converted_audio_file, 'rb')
    audio_samples = audio_samples / float(MAX_ABS_INT16)
    
    print(f'Sample rate: {sample_rate} Hz')
    print(f'Total duration: {len(audio_samples)/sample_rate:.2f}s')
    print(f'Size of the input: {len(audio_samples)}')
    
    # TensorFlow 1.x ìŠ¤íƒ€ì¼ë¡œ ê·¸ë˜í”„ êµ¬ì„±
    print("TensorFlow ê·¸ë˜í”„ êµ¬ì„± ì¤‘...")
    
    # í”Œë ˆì´ìŠ¤í™€ë” ì •ì˜
    audio_input = tf.placeholder(tf.float32, shape=[None], name='audio_input')
    
    # SPICE ëª¨ë¸ ë¡œë“œ
    print("SPICE ëª¨ë¸ ë¡œë”©...")
    model = hub.load("https://tfhub.dev/google/spice/2")
    
    # ëª¨ë¸ ì ìš©
    model_output = model.signatures['serving_default'](input=audio_input)
    
    # ì„¸ì…˜ ì‹œì‘
    print("TensorFlow ì„¸ì…˜ ì‹œì‘...")
    config = tf.ConfigProto()
    config.allow_soft_placement = True
    
    with tf.Session(config=config) as sess:
        print("ë³€ìˆ˜ ì´ˆê¸°í™”...")
        
        # ëª¨ë“  ì´ˆê¸°í™” ì‘ì—…
        try:
            # SavedModel ì´ˆê¸°í™”ìë“¤ ì‹¤í–‰
            saved_model_initializers = tf.get_collection("saved_model_initializers")
            if saved_model_initializers:
                print(f"SavedModel ì´ˆê¸°í™”ì {len(saved_model_initializers)}ê°œ ì‹¤í–‰ ì¤‘...")
                sess.run(saved_model_initializers)
            
            # ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
            global_init = tf.global_variables_initializer()
            sess.run(global_init)
            
            # ë¡œì»¬ ë³€ìˆ˜ ì´ˆê¸°í™”
            local_init = tf.local_variables_initializer()
            sess.run(local_init)
            
            print("ëª¨ë“  ë³€ìˆ˜ ì´ˆê¸°í™” ì™„ë£Œ!")
            
        except Exception as init_error:
            print(f"ì´ˆê¸°í™” ì˜¤ë¥˜: {init_error}")
            print("ì´ˆê¸°í™” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰...")
        
        # SPICE ëª¨ë¸ ì‹¤í–‰
        print("SPICE ëª¨ë¸ë¡œ í”¼ì¹˜ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        
        try:
            feed_dict = {audio_input: audio_samples}
            
            pitch_outputs, uncertainty_outputs = sess.run([
                model_output['pitch'], 
                model_output['uncertainty']
            ], feed_dict=feed_dict)
            
            print("ğŸ‰ SPICE ëª¨ë¸ ì‹¤í–‰ ì„±ê³µ!")
            
            # ê²°ê³¼ ë¶„ì„
            confidence_outputs = 1.0 - uncertainty_outputs
            
            print(f"í”¼ì¹˜ ì¶œë ¥ ê¸¸ì´: {len(pitch_outputs)}")
            print(f"í‰ê·  ì‹ ë¢°ë„: {np.mean(confidence_outputs):.3f}")
            print(f"í”¼ì¹˜ ë²”ìœ„: {np.min(pitch_outputs):.3f} ~ {np.max(pitch_outputs):.3f}")
            
            # ì‹ ë¢°ë„ ë†’ì€ í”¼ì¹˜ë§Œ ì„ íƒ
            high_confidence_mask = confidence_outputs >= 0.9
            high_confidence_pitches = pitch_outputs[high_confidence_mask]
            
            print(f"ë†’ì€ ì‹ ë¢°ë„ í”¼ì¹˜ ê°œìˆ˜: {len(high_confidence_pitches)}")
            
            if len(high_confidence_pitches) > 0:
                print(f"ë†’ì€ ì‹ ë¢°ë„ í”¼ì¹˜ ë²”ìœ„: {np.min(high_confidence_pitches):.3f} ~ {np.max(high_confidence_pitches):.3f}")
            
            # ê²°ê³¼ ì‹œê°í™”
            fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 10))
            
            # ì›ë³¸ ì˜¤ë””ì˜¤
            ax1.plot(audio_samples[:8000])
            ax1.set_title('ì›ë³¸ ì˜¤ë””ì˜¤ íŒŒí˜• (ì²˜ìŒ 0.5ì´ˆ)')
            ax1.set_ylabel('ì§„í­')
            
            # SPICE í”¼ì¹˜ì™€ ì‹ ë¢°ë„
            ax2.plot(pitch_outputs, label='Pitch', alpha=0.7)
            ax2.plot(confidence_outputs, label='Confidence', alpha=0.7)
            ax2.set_title('SPICE í”¼ì¹˜ ë¶„ì„ ê²°ê³¼')
            ax2.set_ylabel('ê°’')
            ax2.legend()
            ax2.grid(True)
            
            # ë†’ì€ ì‹ ë¢°ë„ í”¼ì¹˜ë§Œ
            high_conf_indices = np.where(high_confidence_mask)[0]
            if len(high_conf_indices) > 0:
                ax3.scatter(high_conf_indices, high_confidence_pitches, c='red', s=2, alpha=0.6)
                ax3.set_title('ë†’ì€ ì‹ ë¢°ë„ í”¼ì¹˜ (ì‹ ë¢°ë„ >= 0.9)')
                ax3.set_xlabel('ì‹œê°„ í”„ë ˆì„')
                ax3.set_ylabel('í”¼ì¹˜ ê°’')
                ax3.grid(True)
            
            plt.tight_layout()
            plt.savefig('spice_results.png', dpi=150, bbox_inches='tight')
            plt.show()
            
            print("SPICE ë¶„ì„ ê²°ê³¼ê°€ spice_results.pngì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("SPICE ëª¨ë¸ ì‹¤í–‰ ì™„ì „ ì„±ê³µ! ğŸŠ")
            
        except Exception as run_error:
            print(f"ëª¨ë¸ ì‹¤í–‰ ì˜¤ë¥˜: {run_error}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()